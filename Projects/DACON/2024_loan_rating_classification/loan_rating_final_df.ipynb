{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m6YEbuZgNzX",
        "outputId": "083a5e09-ec58-4d5d-e59a-d3644e514c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOadHm6SgOe3",
        "outputId": "5bec2a6c-46f8-41bb-cd24-4f5fa63c823c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ny1icDQgPLB",
        "outputId": "7282f081-de61-4f42-b3b3-588a84509e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FrVusLMH18NO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import gc\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager, rc\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, PowerTransformer, OrdinalEncoder,\n",
        "    OneHotEncoder, FunctionTransformer, PolynomialFeatures, LabelEncoder\n",
        ")\n",
        "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression, LinearRegression, Ridge, Lasso,\n",
        "    SGDRegressor, ElasticNet\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, cross_validate,\n",
        "    GridSearchCV, KFold, cross_val_predict\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, mean_squared_error, make_scorer, accuracy_score, log_loss\n",
        ")\n",
        "from sklearn import set_config, datasets\n",
        "from catboost import (\n",
        "    CatBoostRegressor, CatBoostClassifier\n",
        ")\n",
        "from sklearn.pipeline import (\n",
        "    Pipeline, FeatureUnion, make_pipeline\n",
        ")\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, StackingClassifier, StackingRegressor,\n",
        "    GradientBoostingRegressor, VotingClassifier, VotingRegressor,\n",
        "    HistGradientBoostingRegressor, GradientBoostingClassifier,\n",
        "    BaggingClassifier, AdaBoostClassifier, RandomForestRegressor,ExtraTreesRegressor\n",
        ")\n",
        "\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "from sklearn.svm import SVC, SVR, LinearSVC\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import re\n",
        "import optuna\n",
        "import math\n",
        "from pandas.errors import DataError\n",
        "from scipy.stats import zscore\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YaKOdbov18NQ"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cjdRAEZP18NQ"
      },
      "outputs": [],
      "source": [
        "#데이터 로드\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/3-2/머신러닝/dacon/고객 대출등급 분류 해커톤/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/3-2/머신러닝/dacon/고객 대출등급 분류 해커톤/test.csv\")\n",
        "\n",
        "# #데이터 로드\n",
        "# train = pd.read_csv(\"train.csv\")\n",
        "# test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuUxyQJPgEIE",
        "outputId": "ba65fb1c-454a-495a-836c-e6925fe4042e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전처리 전 train 크기 : (96294, 15)\n",
            "전처리 전 test 크기 : (64197, 14)\n",
            "=================전처리 중=================\n",
            "전처리 후 train 크기 : (96294, 15)\n",
            "전처리 후 test 크기 : (64197, 14)\n"
          ]
        }
      ],
      "source": [
        "#전처리\n",
        "def pre_all(train, test):\n",
        "    print(f\"전처리 전 train 크기 : {train.shape}\")\n",
        "    print(f\"전처리 전 test 크기 : {test.shape}\")\n",
        "    print(\"=================전처리 중=================\")\n",
        "\n",
        "    df = pd.concat([train,test]).reset_index(drop = True)\n",
        "\n",
        "\n",
        "    df['근로기간'] = df['근로기간'].replace({\n",
        "        '10+ years' : '10',\n",
        "        '2 years' : '2',\n",
        "        '< 1 year' : '1',\n",
        "        '3 years' : '3',\n",
        "        '1 year' : '1',\n",
        "        'Unknown' : '12',\n",
        "        '5 years' : '5',\n",
        "        '4 years' : '4',\n",
        "        '8 years' : '8',\n",
        "        '6 years' : '6',\n",
        "        '7 years' : '7',\n",
        "        '9 years' : '9',\n",
        "        '10+years': '10',\n",
        "        '<1 year' : '1',\n",
        "        '1 years' : '1'\n",
        "    })\n",
        "    df['근로기간'] = df['근로기간'].astype('int64')\n",
        "\n",
        "    #대출기간 전처리\n",
        "    def preprocess_loan_term(term):\n",
        "        if pd.isnull(term):\n",
        "            return None\n",
        "        else:\n",
        "            return int(term.replace(' months', '').strip())\n",
        "    df['대출기간'] = df['대출기간'].apply(preprocess_loan_term)\n",
        "\n",
        "    train = df[~df[\"대출등급\"].isnull()].sort_values(\"ID\").reset_index(drop = True)\n",
        "    test = df[df[\"대출등급\"].isnull()].sort_values(\"ID\").reset_index(drop=True)\n",
        "    test = test.drop(columns=[\"대출등급\"])\n",
        "\n",
        "    print(f\"전처리 후 train 크기 : {train.shape}\")\n",
        "    print(f\"전처리 후 test 크기 : {test.shape}\")\n",
        "\n",
        "    return train, test\n",
        "\n",
        "train_pre, test_pre = pre_all(train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yE05j1x8gEIF"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_pre.대출등급= label_encoder.fit_transform(train.대출등급)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbrN71_gEIF"
      },
      "source": [
        "# 총상환원금"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QNu8VsEzgEIG"
      },
      "outputs": [],
      "source": [
        "train_pre['상환여부'] = (train_pre['총상환원금'] + train_pre['총상환이자'] > 0).astype(int)\n",
        "train_pre['상환여부_원금'] = (train_pre['총상환원금'] > 0).astype(int)\n",
        "train_pre['상환여부_이자'] = (train_pre['총상환이자'] > 0).astype(int)\n",
        "\n",
        "test_pre['상환여부'] = (test_pre['총상환원금'] + test_pre['총상환이자'] > 0).astype(int)\n",
        "test_pre['상환여부_원금'] = (test_pre['총상환원금'] > 0).astype(int)\n",
        "test_pre['상환여부_이자'] = (test_pre['총상환이자'] > 0).astype(int)\n",
        "\n",
        "#OHE\n",
        "cat = ['주택소유상태','대출목적']\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "ohe.fit(train_pre[cat])\n",
        "columns = []\n",
        "for i, c in enumerate(cat):\n",
        "    columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
        "# 생성된 dummy를 DataFrame으로 변환\n",
        "df_ohe = pd.DataFrame(ohe.transform(train_pre[cat]), columns=columns)\n",
        "# 인코딩한 feature는 제거하고 나머지 feature와 결합\n",
        "train_pre= pd.concat([train_pre.drop(columns=cat).reset_index(drop=True), df_ohe], axis=1) # 원래 피처 삭제 후 OHE된 feature 병합\n",
        "\n",
        "columns = []\n",
        "for i, c in enumerate(cat):\n",
        "    columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
        "# 생성된 dummy를 DataFrame으로 변환\n",
        "df_ohe = pd.DataFrame(ohe.transform(test_pre[cat]), columns=columns)\n",
        "# 인코딩한 feature는 제거하고 나머지 feature와 결합\n",
        "test_pre= pd.concat([test_pre.drop(columns=cat).reset_index(drop=True), df_ohe], axis=1) # 원래 피처 삭제 후 OHE된 feature 병합\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dZhpqx0gSWNL"
      },
      "outputs": [],
      "source": [
        "근로기간_train = train_pre[train_pre['근로기간'] != 12]\n",
        "근로기간_test= train_pre[train_pre['근로기간'] == 12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxy_zaazSLWN"
      },
      "outputs": [],
      "source": [
        "# from pycaret.classification import *\n",
        "# x_train, x_test, y_train, y_test = train_test_split(근로기간_train.drop(columns=[\"ID\"]), 근로기간_train['근로기간'])\n",
        "# exp_clf = setup(data=x_train, target='근로기간', session_id=123 ,  use_gpu=True)\n",
        "\n",
        "# best_model = compare_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuaRcTTcWN9i",
        "outputId": "12190340-24c2-4b7f-d26e-d23e46038488"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 04:56:58,889] A new study created in memory with name: no-name-a79becaf-4e6c-4633-ae07-a212fba5ef17\n",
            "[I 2024-02-02 04:57:30,727] Trial 0 finished with value: 0.6353404200537021 and parameters: {'n_estimators': 52, 'learning_rate': 0.25283975689807814, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.6353404200537021.\n",
            "[I 2024-02-02 04:58:34,455] Trial 1 finished with value: 0.6347519034832825 and parameters: {'n_estimators': 292, 'learning_rate': 0.004996882868239982, 'algorithm': 'SAMME'}. Best is trial 1 with value: 0.6347519034832825.\n",
            "[I 2024-02-02 04:59:15,069] Trial 2 finished with value: 0.6460808474638614 and parameters: {'n_estimators': 380, 'learning_rate': 0.0014915582688123652, 'algorithm': 'SAMME.R'}. Best is trial 1 with value: 0.6347519034832825.\n",
            "[I 2024-02-02 05:00:02,084] Trial 3 finished with value: 0.6326553132011623 and parameters: {'n_estimators': 438, 'learning_rate': 0.21839141511364094, 'algorithm': 'SAMME.R'}. Best is trial 3 with value: 0.6326553132011623.\n",
            "[I 2024-02-02 05:00:22,008] Trial 4 finished with value: 0.6329863537720234 and parameters: {'n_estimators': 184, 'learning_rate': 0.454293588005812, 'algorithm': 'SAMME.R'}. Best is trial 3 with value: 0.6326553132011623.\n",
            "[I 2024-02-02 05:01:07,807] Trial 5 finished with value: 0.6347519034832825 and parameters: {'n_estimators': 497, 'learning_rate': 0.006098937453173132, 'algorithm': 'SAMME'}. Best is trial 3 with value: 0.6326553132011623.\n",
            "[I 2024-02-02 05:01:52,168] Trial 6 finished with value: 0.6320300143450914 and parameters: {'n_estimators': 406, 'learning_rate': 0.2007141895179214, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:02:18,396] Trial 7 finished with value: 0.6460808474638614 and parameters: {'n_estimators': 320, 'learning_rate': 0.0012840818540282091, 'algorithm': 'SAMME'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:03:07,207] Trial 8 finished with value: 0.6460808474638614 and parameters: {'n_estimators': 438, 'learning_rate': 0.0013132983962915927, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:03:27,780] Trial 9 finished with value: 0.6350093794828411 and parameters: {'n_estimators': 196, 'learning_rate': 0.04010054221072458, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:03:50,069] Trial 10 finished with value: 0.634531209769375 and parameters: {'n_estimators': 206, 'learning_rate': 0.06339764283437962, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:04:49,222] Trial 11 finished with value: 0.6325817486298599 and parameters: {'n_estimators': 396, 'learning_rate': 0.9827516699858561, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:05:28,392] Trial 12 finished with value: 0.6328024423437673 and parameters: {'n_estimators': 361, 'learning_rate': 0.921863642541437, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:06:12,127] Trial 13 finished with value: 0.6321403612020451 and parameters: {'n_estimators': 416, 'learning_rate': 0.13721815175192706, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:07:03,204] Trial 14 finished with value: 0.6321403612020451 and parameters: {'n_estimators': 473, 'learning_rate': 0.10057195597105428, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:07:39,992] Trial 15 finished with value: 0.6358921543384706 and parameters: {'n_estimators': 344, 'learning_rate': 0.015767883013411768, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:08:05,159] Trial 16 finished with value: 0.6328024423437673 and parameters: {'n_estimators': 243, 'learning_rate': 0.11595740606451313, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:08:50,901] Trial 17 finished with value: 0.6347886857689337 and parameters: {'n_estimators': 426, 'learning_rate': 0.018693693083033567, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:08:59,971] Trial 18 finished with value: 0.6347886857689337 and parameters: {'n_estimators': 114, 'learning_rate': 0.34304047503161705, 'algorithm': 'SAMME'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:09:32,807] Trial 19 finished with value: 0.6322507080589987 and parameters: {'n_estimators': 310, 'learning_rate': 0.11553449641412215, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:10:16,839] Trial 20 finished with value: 0.6338323463420017 and parameters: {'n_estimators': 418, 'learning_rate': 0.04073919801942858, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:11:11,655] Trial 21 finished with value: 0.6322139257733476 and parameters: {'n_estimators': 500, 'learning_rate': 0.11799344656608104, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:12:04,631] Trial 22 finished with value: 0.6322139257733476 and parameters: {'n_estimators': 468, 'learning_rate': 0.07951135264064596, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:12:55,872] Trial 23 finished with value: 0.6322507080589987 and parameters: {'n_estimators': 473, 'learning_rate': 0.16941075723070895, 'algorithm': 'SAMME.R'}. Best is trial 6 with value: 0.6320300143450914.\n",
            "[I 2024-02-02 05:13:36,243] Trial 24 finished with value: 0.6319196674881378 and parameters: {'n_estimators': 385, 'learning_rate': 0.4096541005881881, 'algorithm': 'SAMME.R'}. Best is trial 24 with value: 0.6319196674881378.\n",
            "[I 2024-02-02 05:14:12,250] Trial 25 finished with value: 0.6330599183433259 and parameters: {'n_estimators': 347, 'learning_rate': 0.5398359791515503, 'algorithm': 'SAMME.R'}. Best is trial 24 with value: 0.6319196674881378.\n",
            "[I 2024-02-02 05:14:33,807] Trial 26 finished with value: 0.6344944274837239 and parameters: {'n_estimators': 262, 'learning_rate': 0.35922264782227065, 'algorithm': 'SAMME'}. Best is trial 24 with value: 0.6319196674881378.\n",
            "[I 2024-02-02 05:15:13,883] Trial 27 finished with value: 0.6321771434876964 and parameters: {'n_estimators': 384, 'learning_rate': 0.616332411424665, 'algorithm': 'SAMME.R'}. Best is trial 24 with value: 0.6319196674881378.\n",
            "[I 2024-02-02 05:15:57,857] Trial 28 finished with value: 0.6320300143450914 and parameters: {'n_estimators': 414, 'learning_rate': 0.20491318914073858, 'algorithm': 'SAMME.R'}. Best is trial 24 with value: 0.6319196674881378.\n",
            "[I 2024-02-02 05:16:04,944] Trial 29 finished with value: 0.6353404200537021 and parameters: {'n_estimators': 79, 'learning_rate': 0.20462894616484656, 'algorithm': 'SAMME'}. Best is trial 24 with value: 0.6319196674881378.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 하이퍼파라미터: {'n_estimators': 385, 'learning_rate': 0.4096541005881881, 'algorithm': 'SAMME.R'}\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        근로기간_train.drop('근로기간', axis=1),\n",
        "        근로기간_train['근로기간'],\n",
        "        test_size=0.3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Change ExtraTreesRegressor to AdaBoostClassifier\n",
        "    classifier = AdaBoostClassifier(\n",
        "        n_estimators=trial.suggest_int('n_estimators', 50, 500),\n",
        "        learning_rate=trial.suggest_loguniform('learning_rate', 0.001, 1.0),\n",
        "        algorithm=trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    classifier.fit(x_train.drop(columns=['ID']), y_train.drop(columns=['ID']))\n",
        "    y_pred = classifier.predict(x_test.drop(columns=['ID']))\n",
        "\n",
        "    # Use accuracy as the metric (you may adjust based on your specific requirements)\n",
        "    accuracy = accuracy_score(y_test.drop(columns=['ID']), y_pred)\n",
        "\n",
        "    return 1 - accuracy  # Minimize the error rate\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "adaboost_best_params_근로기간 = study.best_params\n",
        "print(f\"최적 하이퍼파라미터: {adaboost_best_params_근로기간}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h1CdZuT2SLSB"
      },
      "outputs": [],
      "source": [
        "근로기간_test.drop(columns= ['근로기간'], inplace= True)\n",
        "\n",
        "ada_classification_근로기간 = AdaBoostClassifier(**adaboost_best_params_근로기간)\n",
        "ada_classification_근로기간.fit(근로기간_train.drop(['ID','근로기간','대출등급'], axis=1), 근로기간_train['근로기간'])\n",
        "\n",
        "근로기간_test['근로기간'] = ada_classification_근로기간.predict(근로기간_test.drop(columns=['ID','대출등급']))\n",
        "\n",
        "train_pre = pd.concat([근로기간_train, 근로기간_test], axis=0)\n",
        "\n",
        "train_pre = train_pre.sort_values(by='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JQceXnkRSJCQ"
      },
      "outputs": [],
      "source": [
        "원금_train = train_pre[train_pre['상환여부_원금'] != 0]\n",
        "원금_test= train_pre[train_pre['상환여부_원금'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EjnIMjrgEIG",
        "outputId": "e6612cc0-cc85-48e0-9f6b-504f9106052f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:17:03,687] A new study created in memory with name: no-name-3cc839c0-610e-4363-8e9d-6724e5a346b0\n",
            "[I 2024-02-02 05:17:05,123] Trial 0 finished with value: 985340.6042928292 and parameters: {'n_estimators': 340, 'max_depth': 7, 'min_samples_split': 0.8280270177740388, 'min_samples_leaf': 0.3544196288416567, 'max_features': 'sqrt'}. Best is trial 0 with value: 985340.6042928292.\n",
            "[I 2024-02-02 05:17:05,704] Trial 1 finished with value: 985760.1675167395 and parameters: {'n_estimators': 142, 'max_depth': 19, 'min_samples_split': 0.24363673055601365, 'min_samples_leaf': 0.3451060447532698, 'max_features': 'sqrt'}. Best is trial 0 with value: 985340.6042928292.\n",
            "[I 2024-02-02 05:17:07,613] Trial 2 finished with value: 975466.851685234 and parameters: {'n_estimators': 371, 'max_depth': 5, 'min_samples_split': 0.19661033048527907, 'min_samples_leaf': 0.18493001832910833, 'max_features': 'log2'}. Best is trial 2 with value: 975466.851685234.\n",
            "[I 2024-02-02 05:17:09,321] Trial 3 finished with value: 988272.7231346221 and parameters: {'n_estimators': 432, 'max_depth': 6, 'min_samples_split': 0.9653008892566881, 'min_samples_leaf': 0.41888531824069075, 'max_features': 'sqrt'}. Best is trial 2 with value: 975466.851685234.\n",
            "[I 2024-02-02 05:17:09,959] Trial 4 finished with value: 976079.2000012677 and parameters: {'n_estimators': 138, 'max_depth': 9, 'min_samples_split': 0.7283029506643116, 'min_samples_leaf': 0.12642855616080345, 'max_features': 'sqrt'}. Best is trial 2 with value: 975466.851685234.\n",
            "[I 2024-02-02 05:17:11,155] Trial 5 finished with value: 989960.1012916999 and parameters: {'n_estimators': 184, 'max_depth': 19, 'min_samples_split': 0.6845865465371698, 'min_samples_leaf': 0.3939098192436049, 'max_features': 'log2'}. Best is trial 2 with value: 975466.851685234.\n",
            "[I 2024-02-02 05:17:15,871] Trial 6 finished with value: 978031.4177648771 and parameters: {'n_estimators': 293, 'max_depth': 17, 'min_samples_split': 0.5034722149560186, 'min_samples_leaf': 0.427619778902092, 'max_features': 'auto'}. Best is trial 2 with value: 975466.851685234.\n",
            "[I 2024-02-02 05:17:21,607] Trial 7 finished with value: 914787.5948491917 and parameters: {'n_estimators': 261, 'max_depth': 18, 'min_samples_split': 0.5147150603106968, 'min_samples_leaf': 0.22660778894412614, 'max_features': 'auto'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:22,543] Trial 8 finished with value: 989249.3908794674 and parameters: {'n_estimators': 225, 'max_depth': 20, 'min_samples_split': 0.4249254218483586, 'min_samples_leaf': 0.42379126352424623, 'max_features': 'sqrt'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:23,373] Trial 9 finished with value: 989482.2235012545 and parameters: {'n_estimators': 201, 'max_depth': 17, 'min_samples_split': 0.4944405423852216, 'min_samples_leaf': 0.46636779486106417, 'max_features': 'sqrt'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:25,795] Trial 10 finished with value: 924711.6333912319 and parameters: {'n_estimators': 63, 'max_depth': 14, 'min_samples_split': 0.33019711859494405, 'min_samples_leaf': 0.25033918034094943, 'max_features': 'auto'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:28,099] Trial 11 finished with value: 924752.340294748 and parameters: {'n_estimators': 75, 'max_depth': 13, 'min_samples_split': 0.37036403600045337, 'min_samples_leaf': 0.2552859286207857, 'max_features': 'auto'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:40,896] Trial 12 finished with value: 916892.2959953293 and parameters: {'n_estimators': 495, 'max_depth': 14, 'min_samples_split': 0.2915020597888466, 'min_samples_leaf': 0.24194262043836115, 'max_features': 'auto'}. Best is trial 7 with value: 914787.5948491917.\n",
            "[I 2024-02-02 05:17:50,768] Trial 13 finished with value: 909629.0154728997 and parameters: {'n_estimators': 493, 'max_depth': 15, 'min_samples_split': 0.6239579992507707, 'min_samples_leaf': 0.20080953291516346, 'max_features': 'auto'}. Best is trial 13 with value: 909629.0154728997.\n",
            "[I 2024-02-02 05:17:57,854] Trial 14 finished with value: 899474.2310086135 and parameters: {'n_estimators': 279, 'max_depth': 11, 'min_samples_split': 0.6285277196501998, 'min_samples_leaf': 0.1592766271228112, 'max_features': 'auto'}. Best is trial 14 with value: 899474.2310086135.\n",
            "[I 2024-02-02 05:18:09,758] Trial 15 finished with value: 892010.5299304769 and parameters: {'n_estimators': 487, 'max_depth': 10, 'min_samples_split': 0.6198594902282984, 'min_samples_leaf': 0.10521689053600392, 'max_features': 'auto'}. Best is trial 15 with value: 892010.5299304769.\n",
            "[I 2024-02-02 05:18:16,082] Trial 16 finished with value: 928731.0575194578 and parameters: {'n_estimators': 415, 'max_depth': 10, 'min_samples_split': 0.7928804500358482, 'min_samples_leaf': 0.13203646949647485, 'max_features': 'auto'}. Best is trial 15 with value: 892010.5299304769.\n",
            "[I 2024-02-02 05:18:24,388] Trial 17 finished with value: 890346.48205793 and parameters: {'n_estimators': 331, 'max_depth': 3, 'min_samples_split': 0.6015381854446145, 'min_samples_leaf': 0.10942170518483632, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:25,967] Trial 18 finished with value: 978571.4884059638 and parameters: {'n_estimators': 428, 'max_depth': 3, 'min_samples_split': 0.9590904108380618, 'min_samples_leaf': 0.10541802990534696, 'max_features': 'log2'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:30,508] Trial 19 finished with value: 952614.8591169092 and parameters: {'n_estimators': 331, 'max_depth': 3, 'min_samples_split': 0.8304321338065493, 'min_samples_leaf': 0.2864178461545516, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:39,752] Trial 20 finished with value: 900523.934906488 and parameters: {'n_estimators': 384, 'max_depth': 9, 'min_samples_split': 0.5991466758636091, 'min_samples_leaf': 0.16668091352784697, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:46,754] Trial 21 finished with value: 902098.3241611016 and parameters: {'n_estimators': 289, 'max_depth': 11, 'min_samples_split': 0.6493781634164933, 'min_samples_leaf': 0.15537514454514562, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:51,641] Trial 22 finished with value: 921704.9497949468 and parameters: {'n_estimators': 262, 'max_depth': 8, 'min_samples_split': 0.7290449612272634, 'min_samples_leaf': 0.11042289972468274, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:18:59,033] Trial 23 finished with value: 896231.8819370839 and parameters: {'n_estimators': 310, 'max_depth': 12, 'min_samples_split': 0.5644773670588233, 'min_samples_leaf': 0.15358582344281724, 'max_features': 'auto'}. Best is trial 17 with value: 890346.48205793.\n",
            "[I 2024-02-02 05:19:09,030] Trial 24 finished with value: 871908.376144258 and parameters: {'n_estimators': 331, 'max_depth': 12, 'min_samples_split': 0.4332039514422677, 'min_samples_leaf': 0.10118792538734353, 'max_features': 'auto'}. Best is trial 24 with value: 871908.376144258.\n",
            "[I 2024-02-02 05:19:11,886] Trial 25 finished with value: 968603.81098428 and parameters: {'n_estimators': 464, 'max_depth': 5, 'min_samples_split': 0.41682345734428516, 'min_samples_leaf': 0.10282518645417447, 'max_features': 'log2'}. Best is trial 24 with value: 871908.376144258.\n",
            "[I 2024-02-02 05:19:21,463] Trial 26 finished with value: 906452.4955960088 and parameters: {'n_estimators': 367, 'max_depth': 12, 'min_samples_split': 0.43229764843472934, 'min_samples_leaf': 0.20702796977202798, 'max_features': 'auto'}. Best is trial 24 with value: 871908.376144258.\n",
            "[I 2024-02-02 05:19:36,685] Trial 27 finished with value: 866038.3730688131 and parameters: {'n_estimators': 395, 'max_depth': 15, 'min_samples_split': 0.1313157030202053, 'min_samples_leaf': 0.14034205540627606, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:19:49,970] Trial 28 finished with value: 866813.0028325377 and parameters: {'n_estimators': 344, 'max_depth': 16, 'min_samples_split': 0.15768675905481178, 'min_samples_leaf': 0.13797226344388192, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:19:51,817] Trial 29 finished with value: 983977.5513249921 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_split': 0.10959153789094106, 'min_samples_leaf': 0.29781674059575425, 'max_features': 'log2'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:19:57,458] Trial 30 finished with value: 962437.9650114127 and parameters: {'n_estimators': 347, 'max_depth': 16, 'min_samples_split': 0.10960027128535052, 'min_samples_leaf': 0.3445653040423188, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:20:11,247] Trial 31 finished with value: 866229.4718263233 and parameters: {'n_estimators': 345, 'max_depth': 13, 'min_samples_split': 0.17661089208510786, 'min_samples_leaf': 0.1369014638619906, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:20:25,597] Trial 32 finished with value: 867396.419608454 and parameters: {'n_estimators': 353, 'max_depth': 15, 'min_samples_split': 0.195843298010994, 'min_samples_leaf': 0.14041177690954654, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:20:36,571] Trial 33 finished with value: 894597.1288304084 and parameters: {'n_estimators': 355, 'max_depth': 16, 'min_samples_split': 0.19439015482204586, 'min_samples_leaf': 0.18208762388398977, 'max_features': 'auto'}. Best is trial 27 with value: 866038.3730688131.\n",
            "[I 2024-02-02 05:20:51,737] Trial 34 finished with value: 864765.6586877665 and parameters: {'n_estimators': 384, 'max_depth': 14, 'min_samples_split': 0.18646594963858604, 'min_samples_leaf': 0.13363127107447031, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:20:54,397] Trial 35 finished with value: 973905.1332411448 and parameters: {'n_estimators': 447, 'max_depth': 13, 'min_samples_split': 0.2511055355986906, 'min_samples_leaf': 0.18341418888977096, 'max_features': 'sqrt'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:04,227] Trial 36 finished with value: 907192.9115077384 and parameters: {'n_estimators': 392, 'max_depth': 14, 'min_samples_split': 0.1561461550482995, 'min_samples_leaf': 0.21073526299462964, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:06,365] Trial 37 finished with value: 971461.8070597358 and parameters: {'n_estimators': 406, 'max_depth': 17, 'min_samples_split': 0.23540456703770696, 'min_samples_leaf': 0.13454977796480624, 'max_features': 'log2'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:08,984] Trial 38 finished with value: 972443.8331789824 and parameters: {'n_estimators': 456, 'max_depth': 19, 'min_samples_split': 0.15622458930379673, 'min_samples_leaf': 0.17298682138136215, 'max_features': 'sqrt'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:15,002] Trial 39 finished with value: 936367.6221884259 and parameters: {'n_estimators': 234, 'max_depth': 16, 'min_samples_split': 0.28245266058624807, 'min_samples_leaf': 0.27005799140928566, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:21,947] Trial 40 finished with value: 909918.8064555749 and parameters: {'n_estimators': 308, 'max_depth': 18, 'min_samples_split': 0.15199308838996897, 'min_samples_leaf': 0.22223337401437876, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:36,604] Trial 41 finished with value: 865864.8169095838 and parameters: {'n_estimators': 370, 'max_depth': 15, 'min_samples_split': 0.21195227528377852, 'min_samples_leaf': 0.13635301857135307, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:53,094] Trial 42 finished with value: 865822.9490715712 and parameters: {'n_estimators': 427, 'max_depth': 13, 'min_samples_split': 0.2398911619096326, 'min_samples_leaf': 0.1401471239919668, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:21:59,105] Trial 43 finished with value: 962386.6336064979 and parameters: {'n_estimators': 374, 'max_depth': 13, 'min_samples_split': 0.2394837014956487, 'min_samples_leaf': 0.33991230229271574, 'max_features': 'auto'}. Best is trial 34 with value: 864765.6586877665.\n",
            "[I 2024-02-02 05:22:01,594] Trial 44 finished with value: 970446.0369992116 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 0.34999401102532657, 'min_samples_leaf': 0.14739779492694666, 'max_features': 'sqrt'}. Best is trial 34 with value: 864765.6586877665.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 하이퍼파라미터: {'n_estimators': 384, 'max_depth': 14, 'min_samples_split': 0.18646594963858604, 'min_samples_leaf': 0.13363127107447031, 'max_features': 'auto'}\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        원금_train.drop('총상환원금', axis=1),\n",
        "        원금_train['총상환원금'],\n",
        "        test_size=0.3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    regressor = ExtraTreesRegressor(\n",
        "        n_estimators=trial.suggest_int('n_estimators', 50, 500),\n",
        "        max_depth=trial.suggest_int('max_depth', 3, 20),\n",
        "        min_samples_split=trial.suggest_float('min_samples_split', 0.1, 1.0),\n",
        "        min_samples_leaf=trial.suggest_float('min_samples_leaf', 0.1, 0.5),\n",
        "        max_features=trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    regressor.fit(x_train.drop(columns = ['ID']), y_train.drop(columns = ['ID']))\n",
        "    y_pred = regressor.predict(x_test.drop(columns = ['ID']))\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_test.drop(columns = ['ID']), y_pred))\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=40)\n",
        "\n",
        "et_best_params_원금 = study.best_params\n",
        "print(f\"최적 하이퍼파라미터: {et_best_params_원금}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VfIQ-oM8gEIG"
      },
      "outputs": [],
      "source": [
        "원금_test.drop(columns= ['총상환원금'], inplace= True)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "et_regressor_원금 = ExtraTreesRegressor(**et_best_params_원금)\n",
        "et_regressor_원금.fit(원금_train.drop(['ID','총상환원금','대출등급'], axis=1), 원금_train['총상환원금'])\n",
        "\n",
        "원금_test['총상환원금'] = et_regressor_원금.predict(원금_test.drop(columns=['ID','대출등급']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tJtj5mm8fspz"
      },
      "outputs": [],
      "source": [
        "train_pre = pd.concat([원금_train, 원금_test], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pHJ7hX_fffbO"
      },
      "outputs": [],
      "source": [
        "train_pre = train_pre.sort_values(by='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3UlXZ9yfgEIG"
      },
      "outputs": [],
      "source": [
        "이자_train = train_pre[train_pre['상환여부_이자'] != 0]\n",
        "이자_test= train_pre[train_pre['상환여부_이자'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8O8tpagEIG",
        "outputId": "03476b67-c91e-4e86-e239-1946ddb55f5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:22:23,451] A new study created in memory with name: no-name-8392bbe0-2f53-4279-b2ae-c381a54a6a3c\n",
            "[I 2024-02-02 05:22:25,299] Trial 0 finished with value: 437998.2814872672 and parameters: {'n_estimators': 470, 'max_depth': 19, 'min_samples_split': 0.5268146345215683, 'min_samples_leaf': 0.35850143818602953, 'max_features': 'sqrt'}. Best is trial 0 with value: 437998.2814872672.\n",
            "[I 2024-02-02 05:22:26,451] Trial 1 finished with value: 442130.4812926793 and parameters: {'n_estimators': 324, 'max_depth': 20, 'min_samples_split': 0.32078008850712814, 'min_samples_leaf': 0.42829528872294065, 'max_features': 'log2'}. Best is trial 0 with value: 437998.2814872672.\n",
            "[I 2024-02-02 05:22:28,013] Trial 2 finished with value: 441651.03296521096 and parameters: {'n_estimators': 493, 'max_depth': 7, 'min_samples_split': 0.27085203885142894, 'min_samples_leaf': 0.3964092623872304, 'max_features': 'log2'}. Best is trial 0 with value: 437998.2814872672.\n",
            "[I 2024-02-02 05:22:31,206] Trial 3 finished with value: 370447.3244531598 and parameters: {'n_estimators': 228, 'max_depth': 9, 'min_samples_split': 0.9569707694560392, 'min_samples_leaf': 0.14775238757715725, 'max_features': 'auto'}. Best is trial 3 with value: 370447.3244531598.\n",
            "[I 2024-02-02 05:22:39,824] Trial 4 finished with value: 364047.593442844 and parameters: {'n_estimators': 310, 'max_depth': 13, 'min_samples_split': 0.16652306855111135, 'min_samples_leaf': 0.20225360708805346, 'max_features': 'auto'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:40,620] Trial 5 finished with value: 422687.8248479232 and parameters: {'n_estimators': 201, 'max_depth': 17, 'min_samples_split': 0.9535447297214603, 'min_samples_leaf': 0.2088698374828217, 'max_features': 'sqrt'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:44,931] Trial 6 finished with value: 365779.1287183492 and parameters: {'n_estimators': 272, 'max_depth': 4, 'min_samples_split': 0.6954739338730593, 'min_samples_leaf': 0.1177939660870818, 'max_features': 'auto'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:47,626] Trial 7 finished with value: 443875.384860696 and parameters: {'n_estimators': 140, 'max_depth': 6, 'min_samples_split': 0.25015136717091835, 'min_samples_leaf': 0.4918310180181388, 'max_features': 'auto'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:48,793] Trial 8 finished with value: 424808.5891039793 and parameters: {'n_estimators': 185, 'max_depth': 12, 'min_samples_split': 0.6417077202734388, 'min_samples_leaf': 0.20361344448541976, 'max_features': 'log2'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:49,224] Trial 9 finished with value: 443670.5201749224 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 0.6697036322756058, 'min_samples_leaf': 0.47076241988786516, 'max_features': 'sqrt'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:22:57,007] Trial 10 finished with value: 376909.0049048866 and parameters: {'n_estimators': 381, 'max_depth': 15, 'min_samples_split': 0.141586240720803, 'min_samples_leaf': 0.27887482941523783, 'max_features': 'auto'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:23:02,815] Trial 11 finished with value: 366323.7111122744 and parameters: {'n_estimators': 305, 'max_depth': 3, 'min_samples_split': 0.7751645202781353, 'min_samples_leaf': 0.11867253198559097, 'max_features': 'auto'}. Best is trial 4 with value: 364047.593442844.\n",
            "[I 2024-02-02 05:23:11,386] Trial 12 finished with value: 362861.9210724439 and parameters: {'n_estimators': 383, 'max_depth': 13, 'min_samples_split': 0.4381054407247098, 'min_samples_leaf': 0.19834138532658413, 'max_features': 'auto'}. Best is trial 12 with value: 362861.9210724439.\n",
            "[I 2024-02-02 05:23:20,835] Trial 13 finished with value: 376826.204449674 and parameters: {'n_estimators': 399, 'max_depth': 14, 'min_samples_split': 0.4576461014595872, 'min_samples_leaf': 0.2805867892848438, 'max_features': 'auto'}. Best is trial 12 with value: 362861.9210724439.\n",
            "[I 2024-02-02 05:23:30,811] Trial 14 finished with value: 365192.8358306976 and parameters: {'n_estimators': 380, 'max_depth': 12, 'min_samples_split': 0.1064757773184325, 'min_samples_leaf': 0.20823077723373867, 'max_features': 'auto'}. Best is trial 12 with value: 362861.9210724439.\n",
            "[I 2024-02-02 05:23:39,989] Trial 15 finished with value: 371488.69291826885 and parameters: {'n_estimators': 412, 'max_depth': 15, 'min_samples_split': 0.3846359008285975, 'min_samples_leaf': 0.24026431978824836, 'max_features': 'auto'}. Best is trial 12 with value: 362861.9210724439.\n",
            "[I 2024-02-02 05:23:45,458] Trial 16 finished with value: 411284.4613186092 and parameters: {'n_estimators': 330, 'max_depth': 13, 'min_samples_split': 0.19251080616106148, 'min_samples_leaf': 0.3340510111081402, 'max_features': 'auto'}. Best is trial 12 with value: 362861.9210724439.\n",
            "[I 2024-02-02 05:23:52,199] Trial 17 finished with value: 359982.62829227926 and parameters: {'n_estimators': 265, 'max_depth': 17, 'min_samples_split': 0.4041411010698832, 'min_samples_leaf': 0.17198631283506183, 'max_features': 'auto'}. Best is trial 17 with value: 359982.62829227926.\n",
            "[I 2024-02-02 05:23:54,190] Trial 18 finished with value: 414567.8747318449 and parameters: {'n_estimators': 254, 'max_depth': 17, 'min_samples_split': 0.44835473233581585, 'min_samples_leaf': 0.16473201798052758, 'max_features': 'sqrt'}. Best is trial 17 with value: 359982.62829227926.\n",
            "[I 2024-02-02 05:23:56,485] Trial 19 finished with value: 426372.79523856315 and parameters: {'n_estimators': 431, 'max_depth': 17, 'min_samples_split': 0.5639130434521235, 'min_samples_leaf': 0.24832112280847046, 'max_features': 'log2'}. Best is trial 17 with value: 359982.62829227926.\n",
            "[I 2024-02-02 05:24:06,570] Trial 20 finished with value: 348423.425837662 and parameters: {'n_estimators': 357, 'max_depth': 10, 'min_samples_split': 0.37668459285748257, 'min_samples_leaf': 0.10042382823870938, 'max_features': 'auto'}. Best is trial 20 with value: 348423.425837662.\n",
            "[I 2024-02-02 05:24:17,552] Trial 21 finished with value: 356518.5122934292 and parameters: {'n_estimators': 366, 'max_depth': 10, 'min_samples_split': 0.37099938140563204, 'min_samples_leaf': 0.15767880116718067, 'max_features': 'auto'}. Best is trial 20 with value: 348423.425837662.\n",
            "[I 2024-02-02 05:24:29,851] Trial 22 finished with value: 347300.0223668459 and parameters: {'n_estimators': 363, 'max_depth': 10, 'min_samples_split': 0.35227195338930783, 'min_samples_leaf': 0.10634560307382981, 'max_features': 'auto'}. Best is trial 22 with value: 347300.0223668459.\n",
            "[I 2024-02-02 05:24:41,990] Trial 23 finished with value: 346036.4552150804 and parameters: {'n_estimators': 353, 'max_depth': 9, 'min_samples_split': 0.32971491938037, 'min_samples_leaf': 0.10090287839683271, 'max_features': 'auto'}. Best is trial 23 with value: 346036.4552150804.\n",
            "[I 2024-02-02 05:24:58,203] Trial 24 finished with value: 340632.4692695812 and parameters: {'n_estimators': 433, 'max_depth': 8, 'min_samples_split': 0.2964931704532546, 'min_samples_leaf': 0.1137522186194549, 'max_features': 'auto'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:15,059] Trial 25 finished with value: 347073.8363602006 and parameters: {'n_estimators': 444, 'max_depth': 7, 'min_samples_split': 0.2922101640484056, 'min_samples_leaf': 0.1312313202160881, 'max_features': 'auto'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:32,146] Trial 26 finished with value: 348775.90879382315 and parameters: {'n_estimators': 454, 'max_depth': 6, 'min_samples_split': 0.23881889685901653, 'min_samples_leaf': 0.14144086110199328, 'max_features': 'auto'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:47,934] Trial 27 finished with value: 348374.9257647627 and parameters: {'n_estimators': 432, 'max_depth': 8, 'min_samples_split': 0.2867857415803524, 'min_samples_leaf': 0.13625178499141105, 'max_features': 'auto'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:50,202] Trial 28 finished with value: 420041.1839212415 and parameters: {'n_estimators': 499, 'max_depth': 5, 'min_samples_split': 0.5085845691976087, 'min_samples_leaf': 0.18331113972287388, 'max_features': 'log2'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:52,266] Trial 29 finished with value: 425507.26556104835 and parameters: {'n_estimators': 467, 'max_depth': 8, 'min_samples_split': 0.5440858693563309, 'min_samples_leaf': 0.31825400055174285, 'max_features': 'sqrt'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:25:55,517] Trial 30 finished with value: 421702.5849229984 and parameters: {'n_estimators': 434, 'max_depth': 7, 'min_samples_split': 0.20071961090382098, 'min_samples_leaf': 0.23278200489038145, 'max_features': 'sqrt'}. Best is trial 24 with value: 340632.4692695812.\n",
            "[I 2024-02-02 05:26:06,785] Trial 31 finished with value: 339264.75200297945 and parameters: {'n_estimators': 339, 'max_depth': 9, 'min_samples_split': 0.3260309219841774, 'min_samples_leaf': 0.10120034619535977, 'max_features': 'auto'}. Best is trial 31 with value: 339264.75200297945.\n",
            "[I 2024-02-02 05:26:18,412] Trial 32 finished with value: 347172.40345728863 and parameters: {'n_estimators': 336, 'max_depth': 8, 'min_samples_split': 0.3244223615720434, 'min_samples_leaf': 0.1310919174423592, 'max_features': 'auto'}. Best is trial 31 with value: 339264.75200297945.\n",
            "[I 2024-02-02 05:26:34,611] Trial 33 finished with value: 338480.96084618295 and parameters: {'n_estimators': 413, 'max_depth': 9, 'min_samples_split': 0.3097340612111864, 'min_samples_leaf': 0.10033693153563406, 'max_features': 'auto'}. Best is trial 33 with value: 338480.96084618295.\n",
            "[I 2024-02-02 05:26:46,543] Trial 34 finished with value: 336263.40433644113 and parameters: {'n_estimators': 294, 'max_depth': 11, 'min_samples_split': 0.24138442506250507, 'min_samples_leaf': 0.10027684970089015, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:26:48,108] Trial 35 finished with value: 441456.3861167772 and parameters: {'n_estimators': 309, 'max_depth': 11, 'min_samples_split': 0.2267452610480896, 'min_samples_leaf': 0.3780426004912724, 'max_features': 'log2'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:02,060] Trial 36 finished with value: 352954.55892927886 and parameters: {'n_estimators': 402, 'max_depth': 11, 'min_samples_split': 0.16122230737460788, 'min_samples_leaf': 0.15382498896619295, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:12,464] Trial 37 finished with value: 343734.5454938513 and parameters: {'n_estimators': 290, 'max_depth': 9, 'min_samples_split': 0.2844786264124821, 'min_samples_leaf': 0.12421997690178439, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:20,040] Trial 38 finished with value: 425315.4157415111 and parameters: {'n_estimators': 478, 'max_depth': 6, 'min_samples_split': 0.1014984066496912, 'min_samples_leaf': 0.4257064241772072, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:21,074] Trial 39 finished with value: 419943.7651988524 and parameters: {'n_estimators': 223, 'max_depth': 9, 'min_samples_split': 0.47571972079766595, 'min_samples_leaf': 0.18151307469915395, 'max_features': 'log2'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:25,592] Trial 40 finished with value: 369678.7868781462 and parameters: {'n_estimators': 236, 'max_depth': 5, 'min_samples_split': 0.8240743983167602, 'min_samples_leaf': 0.1509938329821759, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:38,781] Trial 41 finished with value: 341994.1981695472 and parameters: {'n_estimators': 292, 'max_depth': 9, 'min_samples_split': 0.2833656096355429, 'min_samples_leaf': 0.11814423594140352, 'max_features': 'auto'}. Best is trial 34 with value: 336263.40433644113.\n",
            "[I 2024-02-02 05:27:50,483] Trial 42 finished with value: 336106.66110535857 and parameters: {'n_estimators': 286, 'max_depth': 11, 'min_samples_split': 0.24902663956979654, 'min_samples_leaf': 0.10014692919264011, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:27:59,856] Trial 43 finished with value: 338222.30750562315 and parameters: {'n_estimators': 197, 'max_depth': 11, 'min_samples_split': 0.19608658958299158, 'min_samples_leaf': 0.10524126554302471, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:07,814] Trial 44 finished with value: 337285.3741316458 and parameters: {'n_estimators': 193, 'max_depth': 11, 'min_samples_split': 0.21082646407773564, 'min_samples_leaf': 0.10081888508836488, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:09,418] Trial 45 finished with value: 412995.3366939991 and parameters: {'n_estimators': 165, 'max_depth': 12, 'min_samples_split': 0.19151722627154094, 'min_samples_leaf': 0.14675402537320054, 'max_features': 'sqrt'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:12,082] Trial 46 finished with value: 348753.76196041825 and parameters: {'n_estimators': 69, 'max_depth': 11, 'min_samples_split': 0.2352570867533625, 'min_samples_leaf': 0.1296761681321106, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:15,721] Trial 47 finished with value: 362098.07729218196 and parameters: {'n_estimators': 143, 'max_depth': 14, 'min_samples_split': 0.15345087654605044, 'min_samples_leaf': 0.1798610073861081, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:24,140] Trial 48 finished with value: 343650.71109169954 and parameters: {'n_estimators': 203, 'max_depth': 12, 'min_samples_split': 0.12819039995027504, 'min_samples_leaf': 0.11765354700547029, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n",
            "[I 2024-02-02 05:28:29,628] Trial 49 finished with value: 356126.1853058004 and parameters: {'n_estimators': 174, 'max_depth': 20, 'min_samples_split': 0.19426667936785402, 'min_samples_leaf': 0.16277842042714685, 'max_features': 'auto'}. Best is trial 42 with value: 336106.66110535857.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 하이퍼파라미터: {'n_estimators': 286, 'max_depth': 11, 'min_samples_split': 0.24902663956979654, 'min_samples_leaf': 0.10014692919264011, 'max_features': 'auto'}\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        이자_train.drop(['ID','총상환이자'], axis=1),\n",
        "        이자_train['총상환이자'],\n",
        "        test_size=0.3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    regressor = ExtraTreesRegressor(\n",
        "        n_estimators=trial.suggest_int('n_estimators', 50, 500),\n",
        "        max_depth=trial.suggest_int('max_depth', 3, 20),\n",
        "        min_samples_split=trial.suggest_float('min_samples_split', 0.1, 1.0),\n",
        "        min_samples_leaf=trial.suggest_float('min_samples_leaf', 0.1, 0.5),\n",
        "        max_features=trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    regressor.fit(x_train, y_train)\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=40)\n",
        "\n",
        "et_best_params_이자 = study.best_params\n",
        "print(f\"최적 하이퍼파라미터: {et_best_params_이자}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gIg22EPlgEIH"
      },
      "outputs": [],
      "source": [
        "이자_test.drop(columns= ['총상환이자'], inplace= True)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "et_regressor_이자 = ExtraTreesRegressor(**et_best_params_이자)\n",
        "et_regressor_이자.fit(이자_train.drop(['ID','총상환이자','대출등급'], axis=1), 이자_train['총상환이자'])\n",
        "\n",
        "이자_test['총상환이자'] = et_regressor_이자.predict(이자_test.drop(columns=['ID','대출등급']))\n",
        "\n",
        "train_pre = pd.concat([이자_train, 이자_test], axis=0)\n",
        "train_pre = train_pre.sort_values(by='ID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nM-JEgdgEIH"
      },
      "source": [
        "# test 셋 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6y0jvl5cgEIH"
      },
      "outputs": [],
      "source": [
        "근로기간_test_test= test_pre[test_pre['근로기간'] == 12]\n",
        "근로기간_test_train= test_pre[test_pre['근로기간'] != 12]\n",
        "근로기간_test_test.drop(columns= ['근로기간'], inplace= True)\n",
        "근로기간_test_test['근로기간'] = ada_classification_근로기간.predict(근로기간_test_test.drop(columns = ['ID']))\n",
        "test_pre = pd.concat([근로기간_test_train, 근로기간_test_test], axis=0)\n",
        "\n",
        "원금_test_test= test_pre[test_pre['상환여부_원금'] == 0]\n",
        "원금_test_train= test_pre[test_pre['상환여부_원금'] != 0]\n",
        "원금_test_test.drop(columns= ['총상환원금'], inplace= True)\n",
        "원금_test_test['총상환원금'] = et_regressor_원금.predict(원금_test_test.drop(columns = ['ID']))\n",
        "test_pre = pd.concat([원금_test_train, 원금_test_test], axis=0)\n",
        "\n",
        "이자_test_train= test_pre[test_pre['상환여부_이자'] != 0]\n",
        "이자_test_test= test_pre[test_pre['상환여부_이자'] == 0]\n",
        "이자_test_test.drop(columns= ['총상환이자'], inplace= True)\n",
        "이자_test_test['총상환이자'] = et_regressor_이자.predict(이자_test_test.drop(columns = ['ID']))\n",
        "test_pre = pd.concat([이자_test_train, 이자_test_test], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8Duj3jKzgBms"
      },
      "outputs": [],
      "source": [
        "test_pre = test_pre.sort_values(by='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTu1g6xl18NQ",
        "outputId": "9220dd71-4965-49fa-c35a-960e2b426a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전처리 전 train 크기 : (96294, 32)\n",
            "전처리 전 test 크기 : (64197, 31)\n",
            "=================전처리 중=================\n",
            "전처리 후 train 크기 : (96294, 46)\n",
            "전처리 후 test 크기 : (64197, 45)\n"
          ]
        }
      ],
      "source": [
        "#전처리\n",
        "def pre_all(train, test):\n",
        "    print(f\"전처리 전 train 크기 : {train_pre.shape}\")\n",
        "    print(f\"전처리 전 test 크기 : {test_pre.shape}\")\n",
        "    print(\"=================전처리 중=================\")\n",
        "\n",
        "    df = pd.concat([train_pre,test_pre]).reset_index(drop = True)\n",
        "\n",
        "    df[\"월_대출금액\"] = round(df[\"대출금액\"] /df[\"대출기간\"],1)\n",
        "    df[\"월_대출대비_소득비율\"] = round((df[\"연간소득\"]/12)/df[\"월_대출금액\"],1)\n",
        "\n",
        "    df[\"계좌수\"] =df[\"총계좌수\"] / (df[\"연체계좌수\"] + 1)\n",
        "\n",
        "    df[\"대출금액_총상환이자_비율\"] = np.where(df[\"총상환이자\"] == 0, np.nan,df[\"대출금액\"] /df[\"총상환이자\"])\n",
        "    df[\"대출금액_총상환이자_비율\"].fillna(0, inplace=True)\n",
        "\n",
        "    df[\"대출금액_총상환원금_비율\"] = np.where(df[\"총상환원금\"] == 0, np.nan,df[\"대출금액\"] /df[\"총상환원금\"])\n",
        "    df[\"대출금액_총상환원금_비율\"].fillna(0, inplace=True)\n",
        "\n",
        "    df[\"상환이자_상환원금\"] =df.apply(lambda x : 0 if x[\"총상환이자\"] == x[\"총상환원금\"] else (1 if x[\"총상환이자\"] > x[\"총상환원금\"] else 2), axis=1)\n",
        "\n",
        "    # \"상환여부\" 피쳐 추가\n",
        "    df['상환여부'] = (df['총상환원금'] + df['총상환이자'] > 0).astype(int)\n",
        "    df['상환여부_원금'] = (df['총상환원금'] > 0).astype(int)\n",
        "    df['상환여부_이자'] = (df['총상환이자'] > 0).astype(int)\n",
        "\n",
        "    df[\"최근_2년간_연체_횟수\"] =df[\"최근_2년간_연체_횟수\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "    df[\"총상환액\"] =df[\"총상환원금\"] + df[\"총상환이자\"]\n",
        "\n",
        "    df[\"소득대비_총상환액_비율\"] =df[\"총상환액\"] /df[\"연간소득\"]\n",
        "    df[\"대출대비_총상환액_비율\"] =df[\"총상환액\"] /df[\"대출금액\"]\n",
        "    df[\"기간대비_총상환액_비율\"] =df[\"총상환액\"] /df[\"대출기간\"]\n",
        "\n",
        "    df[\"대출대비_총상환원금_비율\"] =df[\"총상환원금\"] /df[\"대출금액\"]\n",
        "    df[\"대출대비_총상환이자_비율\"] =df[\"총상환이자\"] /df[\"대출금액\"]\n",
        "\n",
        "    df[\"소득대비_총상환원금_비율\"] =df[\"총상환원금\"] /df[\"연간소득\"]\n",
        "    df[\"소득대비_총상환이자_비율\"] =df[\"총상환이자\"] /df[\"연간소득\"]\n",
        "\n",
        "    df[\"기간대비_총상환원금_비율\"] =df[\"총상환원금\"] /df[\"대출기간\"]\n",
        "    df[\"기간대비_총상환이자_비율\"] =df[\"총상환이자\"] /df[\"대출기간\"]\n",
        "\n",
        "    df[\"월_이자_지불액\"] =df[\"대출금액\"] *df[\"대출금액_총상환이자_비율\"] /df[\"대출기간\"]\n",
        "\n",
        "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "    df.drop([\"총계좌수\", \"연체계좌수\", \"총연체금액\"], axis=1, inplace=True)\n",
        "    # df 분리하기\n",
        "    train = df[~df[\"대출등급\"].isnull()].reset_index(drop = True)\n",
        "    test = df[df[\"대출등급\"].isnull()].reset_index(drop=True)\n",
        "    test = test.drop(columns=[\"대출등급\"])\n",
        "\n",
        "    print(f\"전처리 후 train 크기 : {train.shape}\")\n",
        "    print(f\"전처리 후 test 크기 : {test.shape}\")\n",
        "\n",
        "    return train, test\n",
        "\n",
        "train_pre, test_pre = pre_all(train, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQSXTwgU18NR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0RAfB5n18NT"
      },
      "outputs": [],
      "source": [
        "# def outlier(df, col, z):\n",
        "#     return df[abs(df[col] - np.mean(df[col]))/np.std(df[col])>z].index\n",
        "\n",
        "# def find_z_score_indices(df, col, z_threshold):\n",
        "#     z_scores = zscore(df[col])\n",
        "#     z_indices = np.where(np.abs(z_scores) >= z_threshold)[0]\n",
        "#     return z_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlaJ4zH_18NT"
      },
      "outputs": [],
      "source": [
        "# 연간소득_train_for_z_1 = find_z_score_indices(train_pre, '연간소득', 3)\n",
        "# 총상환원금_train_for_z_1 = find_z_score_indices(train_pre, '총상환원금', 3)\n",
        "# 총상환이자_train_for_z_1 = find_z_score_indices(train_pre, '총상환이자', 3)\n",
        "\n",
        "# 연간소득_test_for_z_1 = find_z_score_indices(test_pre, '연간소득', 3)\n",
        "# 총상환원금_test_for_z_1 = find_z_score_indices(test_pre, '총상환원금', 3)\n",
        "# 총상환이자_test_for_z_1 = find_z_score_indices(test_pre, '총상환이자', 3)\n",
        "\n",
        "# train_pre.loc[outlier(train, '연간소득', 3), \"연간소득\"] = 연간소득_train_for_z_1\n",
        "# train_pre.loc[outlier(train, '총상환원금', 3), \"총상환원금\"] = 총상환원금_train_for_z_1\n",
        "# train_pre.loc[outlier(train, '총상환이자', 3), \"총상환이자\"] = 총상환이자_train_for_z_1\n",
        "\n",
        "# test_pre.loc[outlier(test, '연간소득', 3), \"연간소득\"] = 연간소득_test_for_z_1\n",
        "# test_pre.loc[outlier(test, '총상환원금', 3), '총상환원금'] = 총상환원금_test_for_z_1\n",
        "# test_pre.loc[outlier(test, '총상환이자', 3), '총상환이자'] = 총상환이자_test_for_z_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VRNKZA8U18NT"
      },
      "outputs": [],
      "source": [
        "target = train_pre.대출등급\n",
        "train_pre = train_pre.drop(['ID',\"대출등급\"], axis=1)\n",
        "test_pre = test_pre.drop(['ID'], axis=1)\n",
        "ID_test = test.ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu1BCYrB18NT"
      },
      "source": [
        "# 로그화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wyHuuEX8nlGp"
      },
      "outputs": [],
      "source": [
        "train_pre['총상환원금_총상환이자_곱'] = train_pre['총상환원금'] * train_pre['총상환이자']\n",
        "train_pre['총상환원금_총상환이자_뺄'] = train_pre['총상환원금'] - train_pre['총상환이자']\n",
        "\n",
        "test_pre['총상환원금_총상환이자_곱'] = test_pre['총상환원금'] * test_pre['총상환이자']\n",
        "test_pre['총상환원금_총상환이자_뺄'] = test_pre['총상환원금'] - test_pre['총상환이자']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY0OSSNF18NT"
      },
      "outputs": [],
      "source": [
        "# scaler = StandardScaler()\n",
        "# list_num = ['대출금액', '연간소득','총상환원금','총상환이자', '총연체금액', '월평균소득','대출금액_총상환이자','총상환원금_총상환이자']\n",
        "# train_pre[list_num] = scaler.fit_transform(train_pre[list_num])\n",
        "# test_pre[list_num] = scaler.transform(test_pre[list_num])\n",
        "# log_train = train_pre\n",
        "# log_test = test_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SyrK4_kS18NU"
      },
      "outputs": [],
      "source": [
        "list_num = ['대출금액', '연간소득','총상환원금','총상환이자','월_대출금액', '상환이자_상환원금', '총상환액', '총상환원금_총상환이자_곱']\n",
        "# items_to_exclude에 있는 항목을 제외한 리스트 생성\n",
        "filtered_list_train = [x for x in train_pre.columns if x not in list_num]\n",
        "filtered_list_test = [x for x in test_pre.columns if x not in list_num]\n",
        "\n",
        "log_train = train_pre[list_num].apply(lambda x : np.log(x+1))\n",
        "log_train = pd.concat([train_pre[filtered_list_train], log_train,], axis=1)\n",
        "\n",
        "log_test = test_pre[list_num].apply(lambda x : np.log(x+1))\n",
        "log_test = pd.concat([ test_pre[filtered_list_test],log_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpKuS7dO18NU"
      },
      "source": [
        "# LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kLReSXRJ18NU",
        "outputId": "4a441cb8-cbe7-4f87-8100-4fcfeac88eed"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA()\n",
        "\n",
        "# LDA를 훈련 데이터에 적용\n",
        "lda.fit(log_train, target)\n",
        "lda_transformed_train = lda.transform(log_train)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, lda_transformed_train.shape[1] + 1), lda.explained_variance_ratio_)\n",
        "plt.xlabel('LDA Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Scree Plot for LDA')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KX66ZArv18NU"
      },
      "outputs": [],
      "source": [
        "# LDA수는 가장 적합한 2로 설정해서 다시 적용\n",
        "lda = LDA(n_components=2)\n",
        "\n",
        "lda.fit(log_train, target)\n",
        "lda_transformed_train = lda.transform(log_train)\n",
        "lda_transformed_test = lda.transform(log_test)\n",
        "\n",
        "# LDA로 생성된 칼럼명을 작성하기 위함\n",
        "lda_columns_train = [f'LDA{i+1}' for i in range(lda_transformed_train.shape[1])]\n",
        "lda_columns_test = [f'LDA{i+1}' for i in range(lda_transformed_test.shape[1])]\n",
        "\n",
        "lda_df_train = pd.DataFrame(lda_transformed_train, columns = lda_columns_train)\n",
        "lda_df_test = pd.DataFrame(lda_transformed_test, columns = lda_columns_test)\n",
        "\n",
        "# NumPy 배열을 데이터프레임으로 변환\n",
        "scaled_train = pd.DataFrame(log_train, columns=train_pre.columns, index=train_pre.index)\n",
        "scaled_test = pd.DataFrame(log_test, columns=test_pre.columns, index=test_pre.index)\n",
        "\n",
        "lda_train_x = pd.concat([scaled_train, lda_df_train], axis=1)\n",
        "lda_test_x = pd.concat([scaled_test, lda_df_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCvm7KWt18NU"
      },
      "source": [
        "# smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGsXw6Pg18NU",
        "outputId": "2c0d6f9a-78c9-420f-9fe1-8e0136b04328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클래스 분포 (이전): {0.0: 16772, 1.0: 28817, 2.0: 27623, 3.0: 13354, 4.0: 7354, 5.0: 1954, 6.0: 420}\n",
            "클래스 분포 (이후): {0.0: 28817, 1.0: 28817, 2.0: 28817, 3.0: 28817, 4.0: 28817, 5.0: 28817, 6.0: 28817}\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# SMOTE 적용\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(lda_train_x, target)\n",
        "\n",
        "# SMOTE 이전과 이후의 클래스 분포 확인\n",
        "print(\"클래스 분포 (이전):\", dict(zip(*np.unique(target, return_counts=True))))\n",
        "print(\"클래스 분포 (이후):\", dict(zip(*np.unique(y_resampled, return_counts=True))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekegu6lN18NU"
      },
      "source": [
        "여기서부터 X_resampled, y_resampled로 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPS0DQ2V18NU"
      },
      "source": [
        "# Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g65XNhIJ18NU",
        "outputId": "c082c883-7fe3-4f35-93c7-269778081086"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:29:07,140] A new study created in memory with name: no-name-a5631b48-fca0-4410-84fb-39295ce26e29\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:29:40,725] Trial 0 finished with value: 0.9514391787480836 and parameters: {'subsample': 0.7960173788475091, 'colsample_bytree': 0.7754940755635624, 'learning_rate': 0.07576083817303467, 'max_depth': 27, 'num_leaves': 35}. Best is trial 0 with value: 0.9514391787480836.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092343 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:30:18,888] Trial 1 finished with value: 0.9527044905531707 and parameters: {'subsample': 0.5081890931015095, 'colsample_bytree': 0.5998687207075932, 'learning_rate': 0.03341913498492814, 'max_depth': 21, 'num_leaves': 88}. Best is trial 1 with value: 0.9527044905531707.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115183 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:30:57,690] Trial 2 finished with value: 0.9606044924198317 and parameters: {'subsample': 0.839038390543714, 'colsample_bytree': 0.7254649524514173, 'learning_rate': 0.08025556107822633, 'max_depth': 21, 'num_leaves': 85}. Best is trial 2 with value: 0.9606044924198317.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091533 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:31:28,053] Trial 3 finished with value: 0.9539292566605504 and parameters: {'subsample': 0.9117736012601236, 'colsample_bytree': 0.6430816221711155, 'learning_rate': 0.0706094442888039, 'max_depth': 9, 'num_leaves': 53}. Best is trial 2 with value: 0.9606044924198317.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094060 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:31:56,311] Trial 4 finished with value: 0.9420798433527761 and parameters: {'subsample': 0.6825059897888825, 'colsample_bytree': 0.8639221094178547, 'learning_rate': 0.061381899004961264, 'max_depth': 18, 'num_leaves': 24}. Best is trial 2 with value: 0.9606044924198317.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089026 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:32:23,562] Trial 5 finished with value: 0.9490972383828579 and parameters: {'subsample': 0.9376509524183845, 'colsample_bytree': 0.7505494387892333, 'learning_rate': 0.09173597745903757, 'max_depth': 6, 'num_leaves': 37}. Best is trial 2 with value: 0.9606044924198317.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024496 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:32:51,010] Trial 6 finished with value: 0.9387784581556053 and parameters: {'subsample': 0.8008335877330459, 'colsample_bytree': 0.513417596927058, 'learning_rate': 0.07963190647920797, 'max_depth': 19, 'num_leaves': 16}. Best is trial 2 with value: 0.9606044924198317.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040230 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:33:28,571] Trial 7 finished with value: 0.9617176285380064 and parameters: {'subsample': 0.8162927240522784, 'colsample_bytree': 0.6735559185645827, 'learning_rate': 0.0947300823891042, 'max_depth': 18, 'num_leaves': 76}. Best is trial 7 with value: 0.9617176285380064.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029712 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:34:08,900] Trial 8 finished with value: 0.960951332834449 and parameters: {'subsample': 0.9980156403738187, 'colsample_bytree': 0.9179890894938472, 'learning_rate': 0.09508568653026855, 'max_depth': 13, 'num_leaves': 86}. Best is trial 7 with value: 0.9617176285380064.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:34:43,169] Trial 9 finished with value: 0.9519591803283275 and parameters: {'subsample': 0.7337674757026496, 'colsample_bytree': 0.6135834166595772, 'learning_rate': 0.03671544756587696, 'max_depth': 16, 'num_leaves': 75}. Best is trial 7 with value: 0.9617176285380064.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024772 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:35:19,405] Trial 10 finished with value: 0.9182213588459367 and parameters: {'subsample': 0.6393223574579444, 'colsample_bytree': 0.51274043507867, 'learning_rate': 0.003736810821615505, 'max_depth': 32, 'num_leaves': 64}. Best is trial 7 with value: 0.9617176285380064.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:36:02,931] Trial 11 finished with value: 0.9619698089121328 and parameters: {'subsample': 0.9992913914587053, 'colsample_bytree': 0.9828127930165965, 'learning_rate': 0.0997404718912089, 'max_depth': 12, 'num_leaves': 96}. Best is trial 11 with value: 0.9619698089121328.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036390 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:36:47,406] Trial 12 finished with value: 0.9619834893321796 and parameters: {'subsample': 0.9014751193731703, 'colsample_bytree': 0.9794999666321113, 'learning_rate': 0.09866910006026416, 'max_depth': 12, 'num_leaves': 97}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046053 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:37:30,280] Trial 13 finished with value: 0.9561348539831296 and parameters: {'subsample': 0.9921889517641911, 'colsample_bytree': 0.9963441953156356, 'learning_rate': 0.05417323728715293, 'max_depth': 11, 'num_leaves': 95}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059297 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:38:02,711] Trial 14 finished with value: 0.9514131976574792 and parameters: {'subsample': 0.9072762037531084, 'colsample_bytree': 0.9794477469033902, 'learning_rate': 0.09846184018013851, 'max_depth': 6, 'num_leaves': 97}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031327 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:38:20,845] Trial 15 finished with value: 0.8653521832664488 and parameters: {'subsample': 0.8750609443648801, 'colsample_bytree': 0.8571188397252925, 'learning_rate': 0.034308508536689056, 'max_depth': 3, 'num_leaves': 59}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:39:04,166] Trial 16 finished with value: 0.9213157287543511 and parameters: {'subsample': 0.9535072770819568, 'colsample_bytree': 0.9190557906554032, 'learning_rate': 0.0020298355451079386, 'max_depth': 14, 'num_leaves': 99}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156843 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:39:42,168] Trial 17 finished with value: 0.9586407805762245 and parameters: {'subsample': 0.8889013242192528, 'colsample_bytree': 0.835781609370543, 'learning_rate': 0.0856715275547174, 'max_depth': 9, 'num_leaves': 72}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030793 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:40:16,544] Trial 18 finished with value: 0.9521266325781642 and parameters: {'subsample': 0.9603557351198502, 'colsample_bytree': 0.9468020605539187, 'learning_rate': 0.06769538735190131, 'max_depth': 23, 'num_leaves': 43}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096469 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:40:57,001] Trial 19 finished with value: 0.9428905891877798 and parameters: {'subsample': 0.5368011252197732, 'colsample_bytree': 0.8174674982093131, 'learning_rate': 0.02122783507517502, 'max_depth': 14, 'num_leaves': 82}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100474 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:41:32,963] Trial 20 finished with value: 0.9447496649411377 and parameters: {'subsample': 0.7515118529110529, 'colsample_bytree': 0.9065456911733164, 'learning_rate': 0.04652261429044087, 'max_depth': 7, 'num_leaves': 67}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:42:09,125] Trial 21 finished with value: 0.9619745349246469 and parameters: {'subsample': 0.8450279126628855, 'colsample_bytree': 0.6903802493559179, 'learning_rate': 0.09988149831708343, 'max_depth': 16, 'num_leaves': 77}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101936 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:42:49,042] Trial 22 finished with value: 0.9616245214224354 and parameters: {'subsample': 0.8563030591791955, 'colsample_bytree': 0.7192585920815029, 'learning_rate': 0.09994701294202821, 'max_depth': 12, 'num_leaves': 91}. Best is trial 12 with value: 0.9619834893321796.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:43:34,244] Trial 23 finished with value: 0.962229630589604 and parameters: {'subsample': 0.9351827019578558, 'colsample_bytree': 0.9620380697686646, 'learning_rate': 0.08753700653105062, 'max_depth': 15, 'num_leaves': 100}. Best is trial 23 with value: 0.962229630589604.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099900 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:44:15,083] Trial 24 finished with value: 0.961015660173966 and parameters: {'subsample': 0.7596351383760054, 'colsample_bytree': 0.7992063184450003, 'learning_rate': 0.0884042941839372, 'max_depth': 16, 'num_leaves': 81}. Best is trial 23 with value: 0.962229630589604.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093014 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:44:53,905] Trial 25 finished with value: 0.9621181137715162 and parameters: {'subsample': 0.9232743615879782, 'colsample_bytree': 0.6899346615526138, 'learning_rate': 0.08560947869489004, 'max_depth': 24, 'num_leaves': 91}. Best is trial 23 with value: 0.962229630589604.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025881 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:45:37,376] Trial 26 finished with value: 0.9624176711378533 and parameters: {'subsample': 0.943336496433613, 'colsample_bytree': 0.5625826499722031, 'learning_rate': 0.08525380667144668, 'max_depth': 26, 'num_leaves': 99}. Best is trial 26 with value: 0.9624176711378533.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025375 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:46:19,180] Trial 27 finished with value: 0.960071317571531 and parameters: {'subsample': 0.9433894353238834, 'colsample_bytree': 0.5556918807145564, 'learning_rate': 0.06344435596215557, 'max_depth': 26, 'num_leaves': 91}. Best is trial 26 with value: 0.9624176711378533.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026805 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:47:03,340] Trial 28 finished with value: 0.9629246096249652 and parameters: {'subsample': 0.5988433038045311, 'colsample_bytree': 0.5739012533245045, 'learning_rate': 0.08429114087100556, 'max_depth': 29, 'num_leaves': 100}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:47:47,306] Trial 29 finished with value: 0.9615797419221586 and parameters: {'subsample': 0.6171587924855546, 'colsample_bytree': 0.5627984585786705, 'learning_rate': 0.07604210100302082, 'max_depth': 30, 'num_leaves': 100}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093536 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:48:21,115] Trial 30 finished with value: 0.9565298640056183 and parameters: {'subsample': 0.6264344069535531, 'colsample_bytree': 0.5891474261656343, 'learning_rate': 0.05658383439948094, 'max_depth': 28, 'num_leaves': 69}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090612 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:48:59,959] Trial 31 finished with value: 0.9618832586190537 and parameters: {'subsample': 0.5799781488956335, 'colsample_bytree': 0.6407583203265204, 'learning_rate': 0.0857845244811932, 'max_depth': 25, 'num_leaves': 91}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:49:41,445] Trial 32 finished with value: 0.9612651583015932 and parameters: {'subsample': 0.6872952087575352, 'colsample_bytree': 0.5541656851562802, 'learning_rate': 0.08175532065648469, 'max_depth': 28, 'num_leaves': 89}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090749 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:50:24,790] Trial 33 finished with value: 0.9615897693288852 and parameters: {'subsample': 0.5053768250591152, 'colsample_bytree': 0.7678759925619769, 'learning_rate': 0.07308595078640334, 'max_depth': 23, 'num_leaves': 100}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090059 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:51:02,034] Trial 34 finished with value: 0.9603839475874467 and parameters: {'subsample': 0.9625498131309846, 'colsample_bytree': 0.6281959579535517, 'learning_rate': 0.07658094391839212, 'max_depth': 30, 'num_leaves': 83}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096014 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:51:33,646] Trial 35 finished with value: 0.9576143784129508 and parameters: {'subsample': 0.9282036669596121, 'colsample_bytree': 0.6746747774040041, 'learning_rate': 0.0890011911965571, 'max_depth': 21, 'num_leaves': 50}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090557 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:52:10,847] Trial 36 finished with value: 0.9606124936325386 and parameters: {'subsample': 0.6873182667817317, 'colsample_bytree': 0.5907768700680567, 'learning_rate': 0.06714810109249139, 'max_depth': 24, 'num_leaves': 93}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091112 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:52:49,123] Trial 37 finished with value: 0.9617726068545488 and parameters: {'subsample': 0.8729881385270805, 'colsample_bytree': 0.7137584317530928, 'learning_rate': 0.08102157742995794, 'max_depth': 21, 'num_leaves': 87}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024704 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:53:18,242] Trial 38 finished with value: 0.9503777060611435 and parameters: {'subsample': 0.7873475018006304, 'colsample_bytree': 0.535746324743296, 'learning_rate': 0.09132798609378705, 'max_depth': 32, 'num_leaves': 27}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097492 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:53:54,997] Trial 39 finished with value: 0.9613686921778462 and parameters: {'subsample': 0.7204618843664904, 'colsample_bytree': 0.6491348663405981, 'learning_rate': 0.08333012206488763, 'max_depth': 28, 'num_leaves': 81}. Best is trial 28 with value: 0.9629246096249652.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 매개변수: {'subsample': 0.5988433038045311, 'colsample_bytree': 0.5739012533245045, 'learning_rate': 0.08429114087100556, 'max_depth': 29, 'num_leaves': 100}\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039058 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10284\n",
            "[LightGBM] [Info] Number of data points in the train set: 141203, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.942340\n",
            "[LightGBM] [Info] Start training from score -1.944120\n",
            "[LightGBM] [Info] Start training from score -1.947590\n",
            "[LightGBM] [Info] Start training from score -1.943972\n",
            "[LightGBM] [Info] Start training from score -1.947292\n",
            "[LightGBM] [Info] Start training from score -1.954266\n",
            "[LightGBM] [Info] Start training from score -1.941846\n",
            "최종 모델의 F1-score: 0.9629752791099085\n"
          ]
        }
      ],
      "source": [
        "# lgbm optuna\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the objective function for optimization\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': 7,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'metric': 'multi_logloss',\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 32),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
        "        'random_state' : 42\n",
        "    }\n",
        "\n",
        "\n",
        "    model = LGBMClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    # Make predictions on the validation set\n",
        "    y_pred = model.predict(X_test)\n",
        "    # F1-score 계산\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return f1  # Optuna는 목적 함수를 최대화하려고 시도합니다.\n",
        "\n",
        "# Optuna 스터디 설정\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=35)\n",
        "\n",
        "# 최적화된 매개변수 출력\n",
        "lgbm_best_params = study.best_params\n",
        "print(f\"최적 매개변수: {lgbm_best_params}\")\n",
        "\n",
        "# 최적 매개변수로 최종 모델 훈련\n",
        "best_model = LGBMClassifier(**lgbm_best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# 최종 모델로 테스트 세트에 대한 예측\n",
        "y_pred_final = best_model.predict(X_test)\n",
        "\n",
        "# 최종 모델 성능 평가\n",
        "f1_final = f1_score(y_test, y_pred_final, average='weighted')\n",
        "print(f\"최종 모델의 F1-score: {f1_final}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roVI05gC18NU",
        "outputId": "646cbc68-f362-4ebb-cf38-1e284f399041"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-02 05:54:40,117] A new study created in memory with name: no-name-c57389f4-25e2-4558-8aa1-b73869f7c32b\n",
            "[I 2024-02-02 05:55:00,975] Trial 0 finished with value: 0.8645092720277783 and parameters: {'subsample': 0.23891469982910865, 'colsample_bytree': 0.38041759076104775, 'learning_rate': 0.06177859246360965, 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0.631610426211008}. Best is trial 0 with value: 0.8645092720277783.\n",
            "[I 2024-02-02 05:55:24,490] Trial 1 finished with value: 0.8804390483175595 and parameters: {'subsample': 0.4662630358384211, 'colsample_bytree': 0.5839087267166049, 'learning_rate': 0.0783844874358352, 'max_depth': 3, 'min_child_weight': 14, 'gamma': 0.5951462512487322}. Best is trial 1 with value: 0.8804390483175595.\n",
            "[I 2024-02-02 05:56:30,253] Trial 2 finished with value: 0.9276445494167391 and parameters: {'subsample': 0.6593063305187347, 'colsample_bytree': 0.8321936071710094, 'learning_rate': 0.006144516436716631, 'max_depth': 17, 'min_child_weight': 18, 'gamma': 0.24262656802290772}. Best is trial 2 with value: 0.9276445494167391.\n",
            "[I 2024-02-02 05:57:15,524] Trial 3 finished with value: 0.9185782046689525 and parameters: {'subsample': 0.172707743221794, 'colsample_bytree': 0.5467620458846427, 'learning_rate': 0.011265641101416153, 'max_depth': 20, 'min_child_weight': 9, 'gamma': 0.4644830769934055}. Best is trial 2 with value: 0.9276445494167391.\n",
            "[I 2024-02-02 05:58:28,990] Trial 4 finished with value: 0.9488278220582479 and parameters: {'subsample': 0.9679705735217307, 'colsample_bytree': 0.8905771876263093, 'learning_rate': 0.036930966197592466, 'max_depth': 20, 'min_child_weight': 19, 'gamma': 0.5458099709233133}. Best is trial 4 with value: 0.9488278220582479.\n",
            "[I 2024-02-02 05:59:00,173] Trial 5 finished with value: 0.9049658217719911 and parameters: {'subsample': 0.20720101900789684, 'colsample_bytree': 0.727144579710861, 'learning_rate': 0.045860738028847305, 'max_depth': 5, 'min_child_weight': 6, 'gamma': 0.0064781759194870725}. Best is trial 4 with value: 0.9488278220582479.\n",
            "[I 2024-02-02 05:59:21,421] Trial 6 finished with value: 0.8216145155756432 and parameters: {'subsample': 0.8614363895368123, 'colsample_bytree': 0.5327298262533338, 'learning_rate': 0.028622947739019106, 'max_depth': 3, 'min_child_weight': 15, 'gamma': 0.13157307750921254}. Best is trial 4 with value: 0.9488278220582479.\n",
            "[I 2024-02-02 06:00:40,757] Trial 7 finished with value: 0.9552757223805249 and parameters: {'subsample': 0.38371853638901987, 'colsample_bytree': 0.8129204703694429, 'learning_rate': 0.054966066079049705, 'max_depth': 19, 'min_child_weight': 4, 'gamma': 0.3303866481533493}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:01:39,348] Trial 8 finished with value: 0.947500207575577 and parameters: {'subsample': 0.42849550059604224, 'colsample_bytree': 0.9300647636527534, 'learning_rate': 0.05105741080005024, 'max_depth': 13, 'min_child_weight': 11, 'gamma': 0.32953312399467727}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:02:23,953] Trial 9 finished with value: 0.9481454228393682 and parameters: {'subsample': 0.335129753052139, 'colsample_bytree': 0.36122982631019973, 'learning_rate': 0.09083272905410229, 'max_depth': 20, 'min_child_weight': 18, 'gamma': 0.9417838960975976}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:03:11,946] Trial 10 finished with value: 0.9481324158090072 and parameters: {'subsample': 0.6891713425114437, 'colsample_bytree': 0.16582080334552696, 'learning_rate': 0.06872839598919223, 'max_depth': 10, 'min_child_weight': 1, 'gamma': 0.8531379701067571}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:05:00,224] Trial 11 finished with value: 0.9547170089120864 and parameters: {'subsample': 0.9190209182432088, 'colsample_bytree': 0.9427006687002364, 'learning_rate': 0.03521031317457099, 'max_depth': 16, 'min_child_weight': 6, 'gamma': 0.38540827979469305}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:06:22,592] Trial 12 finished with value: 0.954121324979564 and parameters: {'subsample': 0.6042412969360691, 'colsample_bytree': 0.7446595375284017, 'learning_rate': 0.03827846496639799, 'max_depth': 15, 'min_child_weight': 5, 'gamma': 0.35037095376404376}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:08:15,651] Trial 13 finished with value: 0.9501386061353561 and parameters: {'subsample': 0.8662830971905982, 'colsample_bytree': 0.97498680458594, 'learning_rate': 0.01983595219620906, 'max_depth': 17, 'min_child_weight': 5, 'gamma': 0.42298104944861487}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:09:12,280] Trial 14 finished with value: 0.9524054129110473 and parameters: {'subsample': 0.779894408648959, 'colsample_bytree': 0.7617700375876864, 'learning_rate': 0.056107077877061436, 'max_depth': 10, 'min_child_weight': 7, 'gamma': 0.7156254309797419}. Best is trial 7 with value: 0.9552757223805249.\n",
            "[I 2024-02-02 06:10:44,107] Trial 15 finished with value: 0.9591837432357083 and parameters: {'subsample': 0.49695192779713876, 'colsample_bytree': 0.9846242108982484, 'learning_rate': 0.07606536993509663, 'max_depth': 17, 'min_child_weight': 3, 'gamma': 0.18931950692607435}. Best is trial 15 with value: 0.9591837432357083.\n",
            "[I 2024-02-02 06:11:57,894] Trial 16 finished with value: 0.9610490854757018 and parameters: {'subsample': 0.5052659937319354, 'colsample_bytree': 0.6513106672419129, 'learning_rate': 0.09837681037383134, 'max_depth': 13, 'min_child_weight': 2, 'gamma': 0.19322641741534274}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:13:01,785] Trial 17 finished with value: 0.9510900236490815 and parameters: {'subsample': 0.4916848115715393, 'colsample_bytree': 0.12455720264798742, 'learning_rate': 0.09918932713773976, 'max_depth': 13, 'min_child_weight': 3, 'gamma': 0.13838941295559076}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:13:43,456] Trial 18 finished with value: 0.9472219812814688 and parameters: {'subsample': 0.5465879864341258, 'colsample_bytree': 0.6693437170797156, 'learning_rate': 0.0814721821112818, 'max_depth': 8, 'min_child_weight': 9, 'gamma': 0.03766355146224132}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:14:44,081] Trial 19 finished with value: 0.956709594717118 and parameters: {'subsample': 0.28088996067611766, 'colsample_bytree': 0.4041115061138, 'learning_rate': 0.0979576684457046, 'max_depth': 13, 'min_child_weight': 2, 'gamma': 0.21869306123795462}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:15:44,096] Trial 20 finished with value: 0.9562020475937392 and parameters: {'subsample': 0.7174545002422985, 'colsample_bytree': 0.28820559541449237, 'learning_rate': 0.08128138714465716, 'max_depth': 15, 'min_child_weight': 12, 'gamma': 0.21520693968654833}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:16:39,463] Trial 21 finished with value: 0.9557986445614641 and parameters: {'subsample': 0.3037814383281119, 'colsample_bytree': 0.45697602354892786, 'learning_rate': 0.09895697063895088, 'max_depth': 11, 'min_child_weight': 2, 'gamma': 0.21781095741116585}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:17:48,555] Trial 22 finished with value: 0.960253318914248 and parameters: {'subsample': 0.5271751468083679, 'colsample_bytree': 0.6336580755387937, 'learning_rate': 0.09036880687395762, 'max_depth': 13, 'min_child_weight': 3, 'gamma': 0.1361299222267615}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:18:26,268] Trial 23 finished with value: 0.9446692491605637 and parameters: {'subsample': 0.5597196920590533, 'colsample_bytree': 0.6352987244249266, 'learning_rate': 0.08892066785231205, 'max_depth': 7, 'min_child_weight': 8, 'gamma': 0.10746532577820578}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:19:46,652] Trial 24 finished with value: 0.959461736575153 and parameters: {'subsample': 0.529813791788266, 'colsample_bytree': 0.6536512872143171, 'learning_rate': 0.07298836066084624, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 0.0664246515033578}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:20:38,346] Trial 25 finished with value: 0.9429058794064262 and parameters: {'subsample': 0.10797535976173422, 'colsample_bytree': 0.6506705715256249, 'learning_rate': 0.06844910756265402, 'max_depth': 12, 'min_child_weight': 3, 'gamma': 0.05286949117490958}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:21:43,772] Trial 26 finished with value: 0.9604655076926257 and parameters: {'subsample': 0.6116986860803185, 'colsample_bytree': 0.48611454782661034, 'learning_rate': 0.08953451220243308, 'max_depth': 14, 'min_child_weight': 4, 'gamma': 0.2748003279689955}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:22:30,956] Trial 27 finished with value: 0.9541819439475621 and parameters: {'subsample': 0.6099756860935837, 'colsample_bytree': 0.4833146052242111, 'learning_rate': 0.08743674730401725, 'max_depth': 9, 'min_child_weight': 5, 'gamma': 0.27345078608932527}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:23:29,903] Trial 28 finished with value: 0.9589596324377107 and parameters: {'subsample': 0.7404406720801892, 'colsample_bytree': 0.2721061464954433, 'learning_rate': 0.09241658054856988, 'max_depth': 11, 'min_child_weight': 1, 'gamma': 0.2987175627747744}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:24:54,298] Trial 29 finished with value: 0.9580142217370912 and parameters: {'subsample': 0.41068204058838553, 'colsample_bytree': 0.49206907278209916, 'learning_rate': 0.062451452866489954, 'max_depth': 14, 'min_child_weight': 1, 'gamma': 0.49955551762544015}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:25:51,685] Trial 30 finished with value: 0.9572822749119824 and parameters: {'subsample': 0.6200298637206819, 'colsample_bytree': 0.5787612347240572, 'learning_rate': 0.08373214792176907, 'max_depth': 12, 'min_child_weight': 8, 'gamma': 0.1381197785662185}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:27:05,938] Trial 31 finished with value: 0.9589479120810872 and parameters: {'subsample': 0.5573355805580197, 'colsample_bytree': 0.6123882306455143, 'learning_rate': 0.07556335606466255, 'max_depth': 14, 'min_child_weight': 4, 'gamma': 0.09448746133172907}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:28:16,246] Trial 32 finished with value: 0.9602530418686216 and parameters: {'subsample': 0.5071927194561112, 'colsample_bytree': 0.6799593232639531, 'learning_rate': 0.09299997760690729, 'max_depth': 15, 'min_child_weight': 4, 'gamma': 0.17250803170487106}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:29:23,975] Trial 33 finished with value: 0.9594132976006182 and parameters: {'subsample': 0.4699618090938104, 'colsample_bytree': 0.7048519593968283, 'learning_rate': 0.09140161533791735, 'max_depth': 16, 'min_child_weight': 6, 'gamma': 0.1584238051504523}. Best is trial 16 with value: 0.9610490854757018.\n",
            "[I 2024-02-02 06:30:44,462] Trial 34 finished with value: 0.9618245794905129 and parameters: {'subsample': 0.6422499918916312, 'colsample_bytree': 0.8086826670660491, 'learning_rate': 0.09455797760291614, 'max_depth': 18, 'min_child_weight': 4, 'gamma': 0.2621813466616858}. Best is trial 34 with value: 0.9618245794905129.\n",
            "[I 2024-02-02 06:32:00,066] Trial 35 finished with value: 0.9614542128912876 and parameters: {'subsample': 0.6663197212882819, 'colsample_bytree': 0.792985759247889, 'learning_rate': 0.09466794193825148, 'max_depth': 18, 'min_child_weight': 2, 'gamma': 0.6675550673283792}. Best is trial 34 with value: 0.9618245794905129.\n",
            "[I 2024-02-02 06:33:26,573] Trial 36 finished with value: 0.962179263295949 and parameters: {'subsample': 0.7874269301851476, 'colsample_bytree': 0.8279953910591581, 'learning_rate': 0.08355746968362396, 'max_depth': 18, 'min_child_weight': 2, 'gamma': 0.6147593160647901}. Best is trial 36 with value: 0.962179263295949.\n",
            "[I 2024-02-02 06:34:50,767] Trial 37 finished with value: 0.9616114412512144 and parameters: {'subsample': 0.7714385614137347, 'colsample_bytree': 0.8486275453445865, 'learning_rate': 0.0837034310647521, 'max_depth': 18, 'min_child_weight': 2, 'gamma': 0.6754029759294398}. Best is trial 36 with value: 0.962179263295949.\n",
            "[I 2024-02-02 06:35:54,878] Trial 38 finished with value: 0.9578448177954245 and parameters: {'subsample': 0.7931363855700505, 'colsample_bytree': 0.8365247323949507, 'learning_rate': 0.08408062054660725, 'max_depth': 18, 'min_child_weight': 15, 'gamma': 0.6678810804341901}. Best is trial 36 with value: 0.962179263295949.\n",
            "[I 2024-02-02 06:37:39,584] Trial 39 finished with value: 0.9613644937516154 and parameters: {'subsample': 0.8234849870764692, 'colsample_bytree': 0.8573569052964334, 'learning_rate': 0.07030229269405497, 'max_depth': 19, 'min_child_weight': 1, 'gamma': 0.5883070745107217}. Best is trial 36 with value: 0.962179263295949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최적 매개변수: {'subsample': 0.7874269301851476, 'colsample_bytree': 0.8279953910591581, 'learning_rate': 0.08355746968362396, 'max_depth': 18, 'min_child_weight': 2, 'gamma': 0.6147593160647901}\n",
            "최종 모델의 F1-score: 0.9619246519771174\n"
          ]
        }
      ],
      "source": [
        "#XGB optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.metrics import f1_score\n",
        "# 목표 변수 라벨 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Optuna 최적화를 위한 목적 함수 정의\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 7,\n",
        "        'booster': 'gbtree',\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
        "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
        "        'random_state' : 42\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train_encoded)\n",
        "    y_pred = model.predict(X_test)\n",
        "    f1 = f1_score(y_test_encoded, y_pred, average='weighted')\n",
        "\n",
        "    return f1\n",
        "\n",
        "# Optuna 스터디 설정\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials = 35)\n",
        "\n",
        "# 최적화된 매개변수 출력\n",
        "xgb_best_params = study.best_params\n",
        "print(f\"최적 매개변수: {xgb_best_params}\")\n",
        "\n",
        "# 최적 매개변수로 최종 모델 훈련\n",
        "best_model = xgb.XGBClassifier(**xgb_best_params)\n",
        "best_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# 최종 모델로 테스트 세트에 대한 예측\n",
        "y_pred_final = best_model.predict(X_test)\n",
        "\n",
        "# 예측 결과 디코딩\n",
        "y_pred_final_decoded = label_encoder.inverse_transform(y_pred_final)\n",
        "\n",
        "# 최종 모델 성능 평가\n",
        "f1_final = f1_score(y_test, y_pred_final_decoded, average='weighted')\n",
        "print(f\"최종 모델의 F1-score: {f1_final}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIl0wQda18NV"
      },
      "source": [
        "# shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOJoRhwtG1LV",
        "outputId": "23582955-4616-414d-fdf8-abfead539c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.7/535.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.1 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mIQ9C9Lx18NV",
        "outputId": "795eb629-5a59-43ed-f306-e12ae7249493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084848 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10304\n",
            "[LightGBM] [Info] Number of data points in the train set: 201719, number of used features: 44\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x950 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0fc5a4b5-70b2-4210-8d50-829a1cf21fde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_name</th>\n",
              "      <th>shap_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>LDA1</td>\n",
              "      <td>1.800554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>대출금액_총상환원금_비율</td>\n",
              "      <td>0.524065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>총상환원금_총상환이자_뺄</td>\n",
              "      <td>0.476742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>대출대비_총상환원금_비율</td>\n",
              "      <td>0.36779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>상환이자_상환원금</td>\n",
              "      <td>0.283522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>대출대비_총상환이자_비율</td>\n",
              "      <td>0.225561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>대출대비_총상환액_비율</td>\n",
              "      <td>0.179281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>LDA2</td>\n",
              "      <td>0.146024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>대출기간</td>\n",
              "      <td>0.120139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>대출금액_총상환이자_비율</td>\n",
              "      <td>0.103417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>주택소유상태_MORTGAGE</td>\n",
              "      <td>0.077613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>소득대비_총상환이자_비율</td>\n",
              "      <td>0.065984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>대출목적_부채 통합</td>\n",
              "      <td>0.062648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>대출목적_신용 카드</td>\n",
              "      <td>0.05657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>근로기간</td>\n",
              "      <td>0.04895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>주택소유상태_RENT</td>\n",
              "      <td>0.043783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>부채_대비_소득_비율</td>\n",
              "      <td>0.042973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>대출목적_기타</td>\n",
              "      <td>0.034071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>기간대비_총상환이자_비율</td>\n",
              "      <td>0.030034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>계좌수</td>\n",
              "      <td>0.028096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>기간대비_총상환원금_비율</td>\n",
              "      <td>0.027058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>소득대비_총상환원금_비율</td>\n",
              "      <td>0.026484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>총상환이자</td>\n",
              "      <td>0.023731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>월_대출대비_소득비율</td>\n",
              "      <td>0.022891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>연간소득</td>\n",
              "      <td>0.022531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>주택소유상태_OWN</td>\n",
              "      <td>0.021892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>총상환원금</td>\n",
              "      <td>0.01987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>기간대비_총상환액_비율</td>\n",
              "      <td>0.019595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>소득대비_총상환액_비율</td>\n",
              "      <td>0.019343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>월_이자_지불액</td>\n",
              "      <td>0.017551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>최근_2년간_연체_횟수</td>\n",
              "      <td>0.015126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>대출금액</td>\n",
              "      <td>0.013389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>총상환원금_총상환이자_곱</td>\n",
              "      <td>0.013386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>총상환액</td>\n",
              "      <td>0.012694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>월_대출금액</td>\n",
              "      <td>0.010044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>대출목적_소규모 사업</td>\n",
              "      <td>0.008344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>대출목적_주택 개선</td>\n",
              "      <td>0.006413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>대출목적_주택</td>\n",
              "      <td>0.003003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>대출목적_주요 구매</td>\n",
              "      <td>0.001448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>대출목적_이사</td>\n",
              "      <td>0.001031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>대출목적_자동차</td>\n",
              "      <td>0.000721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>대출목적_의료</td>\n",
              "      <td>0.000399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>대출목적_휴가</td>\n",
              "      <td>0.000103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>대출목적_재생 에너지</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>주택소유상태_ANY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>상환여부_이자</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>상환여부_원금</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>상환여부</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc5a4b5-70b2-4210-8d50-829a1cf21fde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fc5a4b5-70b2-4210-8d50-829a1cf21fde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fc5a4b5-70b2-4210-8d50-829a1cf21fde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f9296fb-da29-44f9-ba5e-e50f85307481\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f9296fb-da29-44f9-ba5e-e50f85307481')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f9296fb-da29-44f9-ba5e-e50f85307481 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cd5b51a3-2f9b-4e01-b4b2-d489a32f8952\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('importance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cd5b51a3-2f9b-4e01-b4b2-d489a32f8952 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('importance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        column_name shap_importance\n",
              "46             LDA1        1.800554\n",
              "31    대출금액_총상환원금_비율        0.524065\n",
              "45    총상환원금_총상환이자_뺄        0.476742\n",
              "37    대출대비_총상환원금_비율         0.36779\n",
              "32        상환이자_상환원금        0.283522\n",
              "38    대출대비_총상환이자_비율        0.225561\n",
              "35     대출대비_총상환액_비율        0.179281\n",
              "47             LDA2        0.146024\n",
              "1              대출기간        0.120139\n",
              "30    대출금액_총상환이자_비율        0.103417\n",
              "12  주택소유상태_MORTGAGE        0.077613\n",
              "40    소득대비_총상환이자_비율        0.065984\n",
              "16       대출목적_부채 통합        0.062648\n",
              "18       대출목적_신용 카드         0.05657\n",
              "2              근로기간         0.04895\n",
              "14      주택소유상태_RENT        0.043783\n",
              "4       부채_대비_소득_비율        0.042973\n",
              "15          대출목적_기타        0.034071\n",
              "42    기간대비_총상환이자_비율        0.030034\n",
              "29              계좌수        0.028096\n",
              "41    기간대비_총상환원금_비율        0.027058\n",
              "39    소득대비_총상환원금_비율        0.026484\n",
              "7             총상환이자        0.023731\n",
              "28      월_대출대비_소득비율        0.022891\n",
              "3              연간소득        0.022531\n",
              "13       주택소유상태_OWN        0.021892\n",
              "6             총상환원금         0.01987\n",
              "36     기간대비_총상환액_비율        0.019595\n",
              "34     소득대비_총상환액_비율        0.019343\n",
              "43         월_이자_지불액        0.017551\n",
              "5      최근_2년간_연체_횟수        0.015126\n",
              "0              대출금액        0.013389\n",
              "44    총상환원금_총상환이자_곱        0.013386\n",
              "33             총상환액        0.012694\n",
              "27           월_대출금액        0.010044\n",
              "17      대출목적_소규모 사업        0.008344\n",
              "25       대출목적_주택 개선        0.006413\n",
              "24          대출목적_주택        0.003003\n",
              "23       대출목적_주요 구매        0.001448\n",
              "20          대출목적_이사        0.001031\n",
              "21         대출목적_자동차        0.000721\n",
              "19          대출목적_의료        0.000399\n",
              "26          대출목적_휴가        0.000103\n",
              "22      대출목적_재생 에너지             0.0\n",
              "11       주택소유상태_ANY             0.0\n",
              "10          상환여부_이자             0.0\n",
              "9           상환여부_원금             0.0\n",
              "8              상환여부             0.0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FEATURE SELECTION\n",
        "import shap\n",
        "X_importance = lda_test_x\n",
        "\n",
        "model = LGBMClassifier(**lgbm_best_params).fit(X_resampled, y_resampled)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_importance)\n",
        "\n",
        "shap.summary_plot(shap_values, X_importance, plot_type='bar')\n",
        "\n",
        "shap_sum = np.abs(shap_values).mean(axis=1)[1,:]\n",
        "importance_df = pd.DataFrame([X_importance.columns.tolist(), shap_sum.tolist()]).T\n",
        "importance_df.columns = ['column_name', 'shap_importance']\n",
        "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
        "importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ob9AIqCQ18NV"
      },
      "outputs": [],
      "source": [
        "# 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
        "SHAP_THRESHOLD = 0.001\n",
        "features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
        "X_resampled = X_resampled[features_selected]\n",
        "lda_test_x = lda_test_x[features_selected]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sed_08Wg18NV",
        "outputId": "83a43559-319e-487c-f21f-cdc2c833c5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098292 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9474\n",
            "[LightGBM] [Info] Number of data points in the train set: 201719, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n",
            "[LightGBM] [Info] Start training from score -1.945910\n"
          ]
        }
      ],
      "source": [
        "xgb_clf = xgb.XGBClassifier(**xgb_best_params)\n",
        "lgbm_clf = LGBMClassifier(**lgbm_best_params)\n",
        "vote_model_clf = VotingClassifier(\n",
        "    estimators=[(\"lgbm\", lgbm_clf), (\"xgb\", xgb_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# label_encoder = LabelEncoder()\n",
        "# y_train_encoded = label_encoder.fit_transform(y_resampled)\n",
        "\n",
        "vote_model_clf.fit(X_resampled, y_resampled)\n",
        "y_pred = vote_model_clf.predict(lda_test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "1AAS-lTmQVR7",
        "outputId": "bed4d12b-9254-4bf1-d013-d7a3e9f6ad64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train['대출등급'])  # y_train은 훈련 데이터의 실제 클래스 레이블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcxENwsW18NV",
        "outputId": "8d76106c-28f1-4833-f9d3-cf4bcfaf9f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B' 'C' 'A' ... 'D' 'C' 'A']\n"
          ]
        }
      ],
      "source": [
        "y_pred_original = label_encoder.inverse_transform(y_pred.astype(int))\n",
        "print(y_pred_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBQ5V9aJ6Nef",
        "outputId": "3835bcc6-44e2-494e-fb95-9c1a06f668af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'voting_submission_02월02일07시14분.csv' is ready to submit.\n"
          ]
        }
      ],
      "source": [
        "t = pd.Timestamp.now()\n",
        "fname = f\"voting_submission_{t.month:02}월{t.day:02}일{t.hour:02}시{t.minute:02}분.csv\"\n",
        "pd.DataFrame({'ID': ID_test, '대출등급': y_pred_original}).to_csv(fname, index=False)\n",
        "print(f\"'{fname}' is ready to submit.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
